{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: trafilatura in f:\\fux-issues-bot\\venv\\lib\\site-packages (1.6.2)\n",
      "Requirement already satisfied: certifi in f:\\fux-issues-bot\\venv\\lib\\site-packages (from trafilatura) (2020.6.20)\n",
      "Requirement already satisfied: courlan>=0.9.4 in f:\\fux-issues-bot\\venv\\lib\\site-packages (from trafilatura) (0.9.4)\n",
      "Requirement already satisfied: htmldate>=1.5.1 in f:\\fux-issues-bot\\venv\\lib\\site-packages (from trafilatura) (1.5.1)\n",
      "Requirement already satisfied: justext>=3.0.0 in f:\\fux-issues-bot\\venv\\lib\\site-packages (from trafilatura) (3.0.0)\n",
      "Requirement already satisfied: lxml>=4.9.3 in f:\\fux-issues-bot\\venv\\lib\\site-packages (from trafilatura) (4.9.3)\n",
      "Requirement already satisfied: charset-normalizer>=3.2.0 in f:\\fux-issues-bot\\venv\\lib\\site-packages (from trafilatura) (3.3.0)\n",
      "Collecting urllib3<3,>=1.26 (from trafilatura)\n",
      "  Obtaining dependency information for urllib3<3,>=1.26 from https://files.pythonhosted.org/packages/37/dc/399e63f5d1d96bb643404ee830657f4dfcf8503f5ba8fa3c6d465d0c57fe/urllib3-2.0.5-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.0.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: langcodes>=3.3.0 in f:\\fux-issues-bot\\venv\\lib\\site-packages (from courlan>=0.9.4->trafilatura) (3.3.0)\n",
      "Requirement already satisfied: tld>=0.13 in f:\\fux-issues-bot\\venv\\lib\\site-packages (from courlan>=0.9.4->trafilatura) (0.13)\n",
      "Requirement already satisfied: dateparser>=1.1.2 in f:\\fux-issues-bot\\venv\\lib\\site-packages (from htmldate>=1.5.1->trafilatura) (1.1.8)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\fux-issues-bot\\venv\\lib\\site-packages (from htmldate>=1.5.1->trafilatura) (2.8.2)\n",
      "Requirement already satisfied: pytz in f:\\fux-issues-bot\\venv\\lib\\site-packages (from dateparser>=1.1.2->htmldate>=1.5.1->trafilatura) (2020.1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in f:\\fux-issues-bot\\venv\\lib\\site-packages (from dateparser>=1.1.2->htmldate>=1.5.1->trafilatura) (2020.7.14)\n",
      "Requirement already satisfied: tzlocal in f:\\fux-issues-bot\\venv\\lib\\site-packages (from dateparser>=1.1.2->htmldate>=1.5.1->trafilatura) (5.0.1)\n",
      "Requirement already satisfied: six>=1.5 in f:\\fux-issues-bot\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->htmldate>=1.5.1->trafilatura) (1.15.0)\n",
      "Requirement already satisfied: tzdata in f:\\fux-issues-bot\\venv\\lib\\site-packages (from tzlocal->dateparser>=1.1.2->htmldate>=1.5.1->trafilatura) (2023.3)\n",
      "Requirement already satisfied: backports.zoneinfo in f:\\fux-issues-bot\\venv\\lib\\site-packages (from tzlocal->dateparser>=1.1.2->htmldate>=1.5.1->trafilatura) (0.2.1)\n",
      "Downloading urllib3-2.0.5-py3-none-any.whl (123 kB)\n",
      "   ---------------------------------------- 123.8/123.8 kB ? eta 0:00:00\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.11\n",
      "    Uninstalling urllib3-1.25.11:\n",
      "      Successfully uninstalled urllib3-1.25.11\n",
      "Successfully installed urllib3-2.0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "requests 2.24.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 2.0.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "!pip install spacy\n",
    "!pip install trafilatura\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from requests.models import MissingSchema\n",
    "import spacy\n",
    "import trafilatura\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T12:14:14.963601200Z",
     "start_time": "2023-10-01T12:14:14.930106600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "urls = ['https://website.understandingdata.com/',\n",
    "        'https://sempioneer.com/', ]\n",
    "data = {}\n",
    "\n",
    "for url in urls:\n",
    "    # 1. Obtain the response:\n",
    "    resp = requests.get(url)\n",
    "\n",
    "    # 2. If the response content is 200 - Status Ok, Save The HTML Content:\n",
    "    if resp.status_code == 200:\n",
    "        data[url] = resp.text\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T12:14:18.147278300Z",
     "start_time": "2023-10-01T12:14:16.818062100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rlt: fsb/rss.htm%21contenttype%3Dxml.html\n",
      "rlt: styles/fsb2019/bootstrap.min.css\n",
      "rlt: styles/fsb2019/all.css\n",
      "rlt: styles/fsb/ie_fix.css\n",
      "rlt: fsb.htm\n",
      "rlt: fsb/leadership.htm\n",
      "rlt: fsb/structure.htm\n",
      "rlt: fsb/supplement.htm\n",
      "rlt: fsb/press.htm\n",
      "rlt: fsb/gosuslugi.htm\n",
      "rlt: fsb/corruption.htm\n",
      "rlt: javascript:\n",
      "rlt: javascript:\n",
      "rlt: javascript:\n",
      "rlt: fsb/webreception.htm\n",
      "rlt: fsb/press/message/single.htm%21id%3D10439822%40fsbMessage.html\n",
      "rlt: fsb/press/message/single.htm%21id%3D10439821%40fsbMessage.html\n",
      "rlt: fsb/press/message/single.htm%21id%3D10439818%40fsbMessage.html\n",
      "rlt: fsb/press/message/single.htm%21id%3D10439815%40fsbMessage.html\n",
      "rlt: fsb/press/message.htm\n",
      "rlt: fsb/index/easy.htm\n",
      "rlt: fsb/supplement.htm\n",
      "rlt: fsb/supplement/contact.htm\n",
      "rlt: fsb/supplement/contact_ter_org.htm\n",
      "rlt: fsb/supplement/contantr/mm.htm\n",
      "rlt: fsb/supplement/employ.htm\n",
      "rlt: fsb/supplement/employ/doc1.htm\n",
      "rlt: fsb/supplement/employ/doc2.htm\n",
      "rlt: fsb/supplement/employ/doc3.htm\n",
      "rlt: fsb/supplement/employ/doc4.htm\n",
      "rlt: fsb/supplement/employ/doc8.htm\n",
      "rlt: fsb/supplement/archive.htm\n",
      "rlt: fsb/supplement/archive/izdaniya.htm\n",
      "rlt: fsb/supplement/ipoteka.htm\n",
      "rlt: fsb/supplement/ipoteka/npa.htm\n",
      "rlt: fsb/supplement/ipoteka/ira.htm\n",
      "rlt: fsb/supplement/veteran.htm\n",
      "rlt: fsb/supplement/obzor.htm\n",
      "rlt: fsb/supplement/uplata_gos_poshliny.htm\n",
      "rlt: fsb/npd.htm\n",
      "rlt: fsb/npd/otmenasudami.htm\n",
      "rlt: fsb/npd/obzhalovanue.htm\n",
      "rlt: fsb/npd/terror.htm\n",
      "rlt: fsb/npd/pva.htm\n",
      "rlt: fsb/simbols.htm\n",
      "rlt: fsb/goscontrol.htm\n",
      "rlt: fsb/science.htm\n",
      "rlt: fsb/international.htm\n",
      "rlt: fsb/international/meeting.htm\n",
      "rlt: fsb/international/kommyunike.htm\n",
      "rlt: fsb/international/ksps.htm\n",
      "rlt: fsb/comment.htm\n",
      "rlt: fsb/comment/remark.htm\n",
      "rlt: fsb/comment/ufsb.htm\n",
      "rlt: fsb/comment/rukov.htm\n",
      "rlt: fsb/smi.htm\n",
      "rlt: fsb/smi/interview.htm\n",
      "rlt: fsb/smi/overview.htm\n",
      "rlt: fsb/history.htm\n",
      "rlt: fsb/history/creation.htm\n",
      "rlt: fsb/history/leaders.htm\n",
      "rlt: fsb/history/book.htm\n",
      "rlt: fsb/history/author.htm\n",
      "rlt: fsb/history/organibezvov.htm\n",
      "rlt: fsb/history/yubiley.htm\n",
      "rlt: fsb/history/pogranichnik.htm\n",
      "rlt: fsb/history/archival_material.htm\n",
      "rlt: fsb/history/archival_material/DRGmurmansk.htm\n",
      "rlt: fsb/history/archival_material/RostovskayaOblast.htm\n",
      "rlt: fsb/history/archival_material/varyag.htm\n",
      "rlt: fsb/history/archival_material/japan.htm\n",
      "rlt: fsb/history/archival_material/orel.htm\n",
      "rlt: fsb/history/archival_material/Bashkiriya.htm\n",
      "rlt: fsb/history/archival_material/japanbarbarossa.htm\n",
      "rlt: fsb/history/archival_material/Tver.htm\n",
      "rlt: fsb/history/archival_material/Tula.htm\n",
      "rlt: fsb/history/archival_material/Kursk.htm\n",
      "rlt: fsb/history/archival_material/archangelsk.htm\n",
      "rlt: fsb/history/archival_material/feik_iz_proshlogo.htm\n",
      "rlt: fsb/history/archival_material/Golokoz.htm\n",
      "rlt: fsb/history/archival_material/ukrcompany.htm\n",
      "rlt: fsb/history/archival_material/Baur.htm\n",
      "rlt: fsb/history/archival_material/Dengi.htm\n",
      "rlt: fsb/history/archival_material/Arays.htm\n",
      "rlt: fsb/history/archival_material/OUN.htm\n",
      "rlt: fsb/history/archival_material/stalingrad_80_let.htm\n",
      "rlt: fsb/history/archival_material/Volyn.htm\n",
      "rlt: fsb/history/archival_material/Slovackoe_vosstanie.htm\n",
      "rlt: fsb/history/archival_material/AK.htm\n",
      "rlt: fsb/history/archival_material/AK1.htm\n",
      "rlt: fsb/history/archival_material/Volokolamsk.htm\n",
      "rlt: fsb/history/archival_material/Gavrish.htm\n",
      "rlt: fsb/history/archival_material/Stalingrad.htm\n",
      "rlt: fsb/history/archival_material/Litva.htm\n",
      "rlt: fsb/history/archival_material/Dulag-205.htm\n",
      "rlt: fsb/history/archival_material/Smersh80.htm\n",
      "rlt: fsb/history/archival_material/Baur2.htm\n",
      "rlt: fsb/history/archival_material/Archangelsk2.htm\n",
      "rlt: fsb/history/archival_material/Stalinskiy_process.htm\n",
      "rlt: fsb/history/archival_material/Deti.htm\n",
      "rlt: fsb/history/archival_material/Sherner.htm\n",
      "rlt: fsb/history/archival_material/Kursk_80.htm\n",
      "rlt: fsb/history/archival_material/Latviya.htm\n",
      "rlt: fsb/history/archival_material/Stalino.htm\n",
      "rlt: fsb/history/archival_material/Deti_2.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/ZaitsevFF.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/KovalenkoGY.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/KonokhovSA.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/AfoninAA.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/BirukovLP.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/FilikovGY.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/SapunovPM.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/SmirnovMN.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/KnyazevVI.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/SilaevPM.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/SubachevVE.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/SheludchenkoME.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/BabushkinMP.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/BelyaevMH.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/KuznetsovSA.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/BorisovAD.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/PoluninMP.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/RuminGI.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/SafyanovPV.htm\n",
      "rlt: fsb/history/Pogib_v_boyah_za_Rodinu/TkachenkoIA.htm\n",
      "rlt: fsb/supplement/advice.htm\n",
      "rlt: fsb/premiya.htm\n",
      "rlt: fsb/premiya/2006.htm\n",
      "rlt: fsb/premiya/2008.htm\n",
      "rlt: fsb/premiya/2009.htm\n",
      "rlt: fsb/premiya/2010.htm\n",
      "rlt: fsb/premiya/2011.htm\n",
      "rlt: fsb/premiya/2012.htm\n",
      "rlt: fsb/premiya/2013.htm\n",
      "rlt: fsb/premiya/2014.htm\n",
      "rlt: fsb/premiya/2015.htm\n",
      "rlt: fsb/premiya/2016.htm\n",
      "rlt: fsb/premiya/2017.htm\n",
      "rlt: fsb/premiya/2018.htm\n",
      "rlt: fsb/premiya/2019-2020.htm\n",
      "rlt: fsb/media.htm\n",
      "rlt: fsb/media/video.htm\n",
      "rlt: fsb/media/photomaterials.htm\n",
      "rlt: fsb/media/photomaterials/145_let_Dzerzhinsky.htm\n",
      "rlt: fsb/webreception.htm\n",
      "rlt: fsb/webreception/more.htm\n",
      "rlt: fsb/regions.htm\n",
      "rlt: fsb.htm%21_print%3Dtrue.html\n",
      "rlt: fsb/history/pogranichnik.htm\n",
      "rlt: fsb.htm\n",
      "rlt: fsb/webreception.htm\n",
      "rlt: fsb/supplement.htm\n",
      "rlt: fsb/history.htm\n",
      "rlt: fsb/supplement/advice.htm\n",
      "rlt: fsb/goscontrol.htm\n",
      "rlt: fsb/premiya.htm\n",
      "rlt: fsb/simbols.htm\n",
      "rlt: fsb/comment.htm\n",
      "rlt: fsb/npd.htm\n",
      "rlt: fsb/international.htm\n",
      "rlt: fsb/science.htm\n",
      "rlt: fsb/smi.htm\n",
      "rlt: fsb/regions.htm\n",
      "rlt: fsb/media.htm\n",
      "rlt: fsb/sitemap.htm\n",
      "abs: http://www.fsb.ru/\n",
      "abs: http://ps.fsb.ru/fps/contact/department.htm\n",
      "abs: http://ps.fsb.ru/fps/contact.htm\n",
      "abs: http://ps.fsb.ru/fps/smi/smi.htm\n",
      "abs: http://ps.fsb.ru/\n",
      "abs: http://clsz.fsb.ru/\n",
      "abs: http://osfsb.ru\n",
      "abs: http://government.ru/\n",
      "abs: http://www.dynamo.su/\n",
      "abs: http://ps.fsb.ru/\n",
      "abs: http://ps.fsb.ru/fps/smi/smi.htm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\fux-issues-bot\\venv\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  if sys.path[0] == \"\":\n"
     ]
    }
   ],
   "source": [
    "def beautifulsoup_extract_text_fallback(response_content):\n",
    "    '''\n",
    "    This is a fallback function, so that we can always return a value for text content.\n",
    "    Even for when both Trafilatura and BeautifulSoup are unable to extract the text from a\n",
    "    single URL.\n",
    "    '''\n",
    "\n",
    "    # Create the beautifulsoup object:\n",
    "    soup = BeautifulSoup(response_content, 'html.parser')\n",
    "\n",
    "    # Finding the text:\n",
    "    text = soup.find_all(text=True)\n",
    "\n",
    "    # Remove unwanted tag elements:\n",
    "    cleaned_text = ''\n",
    "    blacklist = [\n",
    "        '[document]',\n",
    "        'noscript',\n",
    "        'header',\n",
    "        'html',\n",
    "        'meta',\n",
    "        'head',\n",
    "        'input',\n",
    "        'script',\n",
    "        'style', ]\n",
    "\n",
    "    # Then we will loop over every item in the extract text and make sure that the beautifulsoup4 tag\n",
    "    # is NOT in the blacklist\n",
    "    for item in text:\n",
    "        if item.parent.name not in blacklist:\n",
    "            cleaned_text += '{} '.format(item)\n",
    "\n",
    "    # Remove any tab separation and strip the text:\n",
    "    cleaned_text = cleaned_text.replace('\\t', '')\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "\n",
    "def extract_text_from_single_web_page(url):\n",
    "    downloaded_url = trafilatura.fetch_url(url)\n",
    "    try:\n",
    "        a = trafilatura.extract(downloaded_url, output_format='json', with_metadata=True, include_comments=False,\n",
    "                                date_extraction_params={'extensive_search': True, 'original_date': True})\n",
    "    except AttributeError:\n",
    "        a = trafilatura.extract(downloaded_url, output_format='json', with_metadata=True,\n",
    "                                date_extraction_params={'extensive_search': True, 'original_date': True})\n",
    "    if a:\n",
    "        json_output = json.loads(a)\n",
    "        return json_output['text'], json_output['text']\n",
    "    else:\n",
    "        try:\n",
    "            resp = requests.get(url)\n",
    "            # We will only extract the text from successful requests:\n",
    "            if resp.status_code == 200:\n",
    "                return resp.content.decode('utf-8'), beautifulsoup_extract_text_fallback(resp.content)\n",
    "            else:\n",
    "                # This line will handle for any failures in both the Trafilature and BeautifulSoup4 functions:\n",
    "                return np.nan\n",
    "        # Handling for any URLs that don't have the correct protocol\n",
    "        except MissingSchema:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "single_url = 'http://www.fsb.ru/'\n",
    "page, text = extract_text_from_single_web_page(url=single_url)\n",
    "#print(page)\n",
    "all_relative = re.findall('href=(\\'|\")(.*?)(\\'|\")', page)\n",
    "for aa in all_relative:\n",
    "    if 'http' in aa[1]:\n",
    "        continue\n",
    "    print(f'rlt: {aa[1]}')\n",
    "\n",
    "all_abs = re.findall('href=(\\'|\")(http.*?)(\\'|\")', page)\n",
    "for aa in all_relative:\n",
    "    if not 'http' in aa[1]:\n",
    "        continue\n",
    "    print(f'abs: {aa[1]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T12:18:20.133202600Z",
     "start_time": "2023-10-01T12:18:19.883628Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
